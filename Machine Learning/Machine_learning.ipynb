{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "As all the variables were identified it's time now to build models to best predict if the listing represents a good deal. But first let's manually identify the listings that fit under a 'good deal' criterion.\n",
    "\n",
    "## Preparing data for Machine Learning\n",
    "\n",
    "After reading listings file with added sentiment score for each listing, I am adding a new column of average price per neighbourhood. On top of being rated as top 25% in each category, I want the place not to be priced higher than corresponding neighbourhood average. This will illiminate luxury places that might be perfect in all senses but are completely unaffordable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read listing data base with added sentiment score\n",
    "df = pd.read_csv('entire_home_listings_sentiment.csv', header=0, parse_dates=['host_since'])\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add average per neighbourhood price column\n",
    "mean_price_neigh = df.groupby('neighbourhood').mean().loc[:,'price'].reset_index()\n",
    "mean_price_neigh.columns = ['neighbourhood', 'mean_price']\n",
    "df_1 = df.merge(mean_price_neigh, on='neighbourhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to mark each listing whether it represents a good deal or not\n",
    "def good_deal(row, df=df_1):\n",
    "    \"\"\"Identify if listing represents a good deal\"\"\"\n",
    "    if row['sentiment'] >= df.sentiment.quantile(0.75):\n",
    "        if row['price'] <= row['mean_price']:\n",
    "            if row['review_scores_rating'] >= df.review_scores_rating.quantile(0.75):\n",
    "                if row['review_scores_accuracy'] >= df.review_scores_accuracy.quantile(0.75):\n",
    "                    if row['review_scores_cleanliness'] >= df.review_scores_cleanliness.quantile(0.75):\n",
    "                        if row['review_scores_checkin'] >= df.review_scores_checkin.quantile(0.75):\n",
    "                            if row['review_scores_communication'] >= df.review_scores_communication.quantile(0.75):\n",
    "                                if row['review_scores_location'] >= df.review_scores_location.quantile(0.75):\n",
    "                                    if row['review_scores_value'] >= df.review_scores_value.quantile(0.75):\n",
    "                                        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each listing apply good_deal function\n",
    "a = []\n",
    "for row in df_1.index:\n",
    "    a.append(good_deal(df_1.loc[row,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 25991 listings there  are 1239 good deals.\n"
     ]
    }
   ],
   "source": [
    "print('Out of {} listings there '.format(len(df_1)),'are {} good deals.'.format(np.sum(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to the database\n",
    "df_1['good_deal'] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as the listings were manually labeled, it's time to separate the data into independent predictors and a target variable. From exploratory data analysis, I discovered that below variables influence occupancy rate, which means that they might be among deciding factors for renters when they are choosing the apartment:\n",
    "- host_response_rate\n",
    "- host_is_superhost\n",
    "- accommodates\n",
    "- host_response_rate\n",
    "- cancellation_policy\n",
    "- instant_bookable\n",
    "- all review_scores variables\n",
    "\n",
    "Most of these variables are continuous and can be added as is. However, some categorical varibales need some transformation.\n",
    "\n",
    "I am also including price, occupancy_rate and sentiment in the list of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start building set of independent variables. First take out all numerical variables I will include\n",
    "X = df_1.loc[:,['host_response_rate', 'host_is_superhost', 'accommodates', 'review_scores_rating', 'review_scores_accuracy',\n",
    "       'review_scores_cleanliness', 'review_scores_checkin',\n",
    "       'review_scores_communication', 'review_scores_location',\n",
    "       'review_scores_value', 'price', 'occupancy_rate', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform categorical variables\n",
    "x = pd.get_dummies(df_1.host_response_time).drop('unknown', axis=1)\n",
    "x.columns = ['rt_few_days', 'rt_day', 'rt_few_hours', 'rt_hour']\n",
    "X = X.join(x)\n",
    "\n",
    "x1 = df_1.instant_bookable.replace({'f':0, 't':1})\n",
    "X = X.join(x1)\n",
    "\n",
    "x2 = pd.get_dummies(df_1.cancellation_policy).drop('moderate', axis=1)\n",
    "x2.columns = ['cp_flexible', 'cp_strict']\n",
    "X = X.join(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a target variable\n",
    "Y = df_1.good_deal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional transformations to predictors will be done before starting to build models. I will transform price into log-price and scale all numerical variables to get them all have mean of 0 and variance of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change price to log-price\n",
    "X.price = np.log(X.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['host_response_rate', 'accommodates',\n",
    "       'review_scores_rating', 'review_scores_accuracy',\n",
    "       'review_scores_cleanliness', 'review_scores_checkin',\n",
    "       'review_scores_communication', 'review_scores_location',\n",
    "       'review_scores_value', 'price', 'occupancy_rate', 'sentiment']\n",
    "categorical = ['host_is_superhost', 'rt_few_days', 'rt_day', 'rt_few_hours', 'rt_hour', 'instant_bookable',\n",
    "       'cp_flexible', 'cp_strict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numerical data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "num = pd.DataFrame(StandardScaler().fit_transform(X[numerical]))\n",
    "num.columns = numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = num.join(X[categorical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save variables to files\n",
    "X.to_csv('independent_variables.csv')\n",
    "pd.DataFrame(Y).to_csv('dependent_variable.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "Since I have a classification problem, I will try few classic approaches first. For all of the models I will split my data into train and test sets. Test set will be reserved for evaluating the goodness of the model at the end. All training and transformations will be done on train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple logistic regression classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "lgr = LogisticRegression(solver='lbfgs')\n",
    "lgr.fit(X_train, y_train)\n",
    "y_lgr_test = lgr.predict(X_test)\n",
    "y_lgr_train = lgr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test data: 0.9744806360605284\n",
      "Accuracy score on train data: 0.9695487275325675\n"
     ]
    }
   ],
   "source": [
    "# check accuracy score\n",
    "print('Accuracy score on test data: {}'.format(metrics.accuracy_score(y_test,y_lgr_test)))\n",
    "print('Accuracy score on train data: {}'.format(metrics.accuracy_score(y_train,y_lgr_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the classic logistic regression delivered amazing accuracy scores.Is it really the case? Let's check some more metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for test data: \n",
      " [[7379   67]\n",
      " [ 132  220]]\n",
      "Confusion matrix for train data: \n",
      " [[17104   202]\n",
      " [  352   535]]\n",
      "Report for test data: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      7446\n",
      "           1       0.77      0.62      0.69       352\n",
      "\n",
      "    accuracy                           0.97      7798\n",
      "   macro avg       0.87      0.81      0.84      7798\n",
      "weighted avg       0.97      0.97      0.97      7798\n",
      "\n",
      "Report for train data: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     17306\n",
      "           1       0.73      0.60      0.66       887\n",
      "\n",
      "    accuracy                           0.97     18193\n",
      "   macro avg       0.85      0.80      0.82     18193\n",
      "weighted avg       0.97      0.97      0.97     18193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix for test data: \\n', metrics.confusion_matrix(y_test,y_lgr_test))\n",
    "print('Confusion matrix for train data: \\n', metrics.confusion_matrix(y_train,y_lgr_train))\n",
    "print('Report for test data: \\n', metrics.classification_report(y_test,y_lgr_test))\n",
    "print('Report for train data: \\n', metrics.classification_report(y_train,y_lgr_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like I am dealing with imbalanced data here and lots of listings (over 30% in good deal category in test data) were classified as not representing a good deal. Some further manipulations of predictors are needed to avoid imbalanced data effects. \n",
    "\n",
    "I will also create a dataframe that will contain results for each classifier. It will help me to compare them later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary first\n",
    "a = {'classifier_name':'Logistic', 'score':metrics.accuracy_score(y_test, y_lgr_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_lgr_test), 'precision': metrics.precision_score(y_test, y_lgr_test),\n",
    "    'recall': metrics.recall_score(y_test, y_lgr_test)}\n",
    "cls_comparison = pd.DataFrame([a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced data\n",
    "\n",
    "There are few techniques that can help to deal with imbalanced data:\n",
    "- Undersampling - evening out the number of samples in each class by randomly reducing the number of samples in the majority class\n",
    "- Oversampling - evening out the number of samples in each classby randomly sampling over minority class with replacemnets to get as many samples as in majority class\n",
    "- SMOTE - Synthetic Minority Over-Sampling Technique - synthesises new minority instances between existing (real) minority instances. \n",
    "\n",
    "### Undersampling\n",
    "\n",
    "I will apply this technique manually by sampling over majority class to get as many samples as minority class contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine predictor and target variables\n",
    "all_imb = X_train.join(y_train)\n",
    "class2 = all_imb[all_imb.good_deal == 1]\n",
    "n = len(class2)\n",
    "# select random samples from majority clasee\n",
    "class1 = all_imb[all_imb.good_deal==0].sample(n)\n",
    "all_bal = pd.concat([class1,class2])\n",
    "X_train_under = all_bal.iloc[:,:-1]\n",
    "y_train_under = all_bal.loc[:,'good_deal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train logistic classifier with balanced data\n",
    "lgr1 = LogisticRegression(solver='lbfgs')\n",
    "lgr1.fit(X_train_under, y_train_under)\n",
    "y_lgu_test = lgr1.predict(X_test)\n",
    "y_lgu_train = lgr1.predict(X_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test data: 0.9157476275968197\n",
      "Accuracy score on train data: 0.9526493799323562\n",
      "Confusion matrix for test data: \n",
      " [[6792  654]\n",
      " [   3  349]]\n",
      "Confusion matrix for train data: \n",
      " [[804  83]\n",
      " [  1 886]]\n",
      "Report for test data: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95      7446\n",
      "           1       0.35      0.99      0.52       352\n",
      "\n",
      "    accuracy                           0.92      7798\n",
      "   macro avg       0.67      0.95      0.73      7798\n",
      "weighted avg       0.97      0.92      0.93      7798\n",
      "\n",
      "Report for train data: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95       887\n",
      "           1       0.91      1.00      0.95       887\n",
      "\n",
      "    accuracy                           0.95      1774\n",
      "   macro avg       0.96      0.95      0.95      1774\n",
      "weighted avg       0.96      0.95      0.95      1774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print new scores\n",
    "print('Accuracy score on test data: {}'.format(metrics.accuracy_score(y_test,y_lgu_test)))\n",
    "print('Accuracy score on train data: {}'.format(metrics.accuracy_score(y_train_under,y_lgu_train)))\n",
    "print('Confusion matrix for test data: \\n', metrics.confusion_matrix(y_test,y_lgu_test))\n",
    "print('Confusion matrix for train data: \\n', metrics.confusion_matrix(y_train_under,y_lgu_train))\n",
    "print('Report for test data: \\n', metrics.classification_report(y_test,y_lgu_test))\n",
    "print('Report for train data: \\n', metrics.classification_report(y_train_under,y_lgu_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Logistic_under', 'score':metrics.accuracy_score(y_test, y_lgu_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_lgu_test), 'precision': metrics.precision_score(y_test, y_lgu_test),\n",
    "    'recall': metrics.recall_score(y_test, y_lgu_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.688576</td>\n",
       "      <td>0.766551</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.974481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic_under</td>\n",
       "      <td>0.515129</td>\n",
       "      <td>0.347956</td>\n",
       "      <td>0.991477</td>\n",
       "      <td>0.915748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  f1_score  precision    recall     score\n",
       "0        Logistic  0.688576   0.766551  0.625000  0.974481\n",
       "0  Logistic_under  0.515129   0.347956  0.991477  0.915748"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling improved significantly recall score (almost 99% of good deals were correctly identified), but the amount of incorrectly labeled non-good deals has increased, which lowered  precision score and overall accuracy and f1 scores.\n",
    "\n",
    "Let's check how oversampling will change classifier performance.\n",
    "\n",
    "## Oversampling\n",
    "\n",
    "In order to perform oversampling on the training data I will use imbalanced-learn package from python. That specifically uses different approaches to restructure imbalanced data into balanced one.\n",
    "\n",
    "RandomOverSampler will perform regular oversamling (evening out number of samples in each class by randomly sampling over minority class to reach majority class quantity of samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# balance training data\n",
    "from imblearn import over_sampling\n",
    "b_smote = over_sampling.RandomOverSampler(random_state=42)\n",
    "X_train_b, y_train_b = b_smote.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model with oversampled data\n",
    "lgr2 = LogisticRegression(solver='lbfgs')\n",
    "lgr2.fit(X_train_b, y_train_b)\n",
    "y_lgo_test = lgr2.predict(X_test)\n",
    "y_lgo_train = lgr2.predict(X_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test data: 0.9353680430879713\n",
      "Accuracy score on train data: 0.9624696637004507\n",
      "Confusion matrix for test data: \n",
      " [[6948  498]\n",
      " [   6  346]]\n",
      "Confusion matrix for train data: \n",
      " [[16152  1154]\n",
      " [  145 17161]]\n",
      "Report for test data: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96      7446\n",
      "           1       0.41      0.98      0.58       352\n",
      "\n",
      "    accuracy                           0.94      7798\n",
      "   macro avg       0.70      0.96      0.77      7798\n",
      "weighted avg       0.97      0.94      0.95      7798\n",
      "\n",
      "Report for train data: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96     17306\n",
      "           1       0.94      0.99      0.96     17306\n",
      "\n",
      "    accuracy                           0.96     34612\n",
      "   macro avg       0.96      0.96      0.96     34612\n",
      "weighted avg       0.96      0.96      0.96     34612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score on test data: {}'.format(metrics.accuracy_score(y_test,y_lgo_test)))\n",
    "print('Accuracy score on train data: {}'.format(metrics.accuracy_score(y_train_b,y_lgo_train)))\n",
    "print('Confusion matrix for test data: \\n', metrics.confusion_matrix(y_test,y_lgo_test))\n",
    "print('Confusion matrix for train data: \\n', metrics.confusion_matrix(y_train_b,y_lgo_train))\n",
    "print('Report for test data: \\n', metrics.classification_report(y_test,y_lgo_test))\n",
    "print('Report for train data: \\n', metrics.classification_report(y_train_b,y_lgo_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Logistic_over', 'score':metrics.accuracy_score(y_test, y_lgo_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_lgo_test), 'precision': metrics.precision_score(y_test, y_lgo_test),\n",
    "    'recall': metrics.recall_score(y_test, y_lgo_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.688576</td>\n",
       "      <td>0.766551</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.974481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic_under</td>\n",
       "      <td>0.515129</td>\n",
       "      <td>0.347956</td>\n",
       "      <td>0.991477</td>\n",
       "      <td>0.915748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic_over</td>\n",
       "      <td>0.578595</td>\n",
       "      <td>0.409953</td>\n",
       "      <td>0.982955</td>\n",
       "      <td>0.935368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  f1_score  precision    recall     score\n",
       "0        Logistic  0.688576   0.766551  0.625000  0.974481\n",
       "0  Logistic_under  0.515129   0.347956  0.991477  0.915748\n",
       "0   Logistic_over  0.578595   0.409953  0.982955  0.935368"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling also did not help to improve results from training over imbalanced data. Lets now use SMOTE technique to get balanced data.\n",
    "\n",
    "## SMOTE\n",
    "\n",
    "SMOTE (synthetic minority oversampling technique) is one of the most commonly used oversampling methods to solve the imbalance problem.\n",
    "It aims to balance class distribution by randomly increasing minority class examples by replicating them.\n",
    "SMOTE synthesises new minority instances between existing minority instances. It generates the virtual training records by linear interpolation for the minority class. These synthetic training records are generated by randomly selecting one or more of the k-nearest neighbors for each example in the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# balance train data using SMOTE\n",
    "sm = over_sampling.SMOTE(random_state=42)#, categorical_features=[12,13,14,15,16,17,18,19])\n",
    "X_train_smote, y_train_smote = sm.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier with SMOTE balanced data\n",
    "lgr3 = LogisticRegression(solver='lbfgs')\n",
    "lgr3.fit(X_train_smote, y_train_smote)\n",
    "y_lgs_test = lgr3.predict(X_test)\n",
    "y_lgs_train = lgr3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on test data: 0.9425493716337523\n",
      "Accuracy score on train data: 0.9426702577914583\n",
      "Confusion matrix for test data: \n",
      " [[7007  439]\n",
      " [   9  343]]\n",
      "Confusion matrix for train data: \n",
      " [[16284  1022]\n",
      " [   21   866]]\n",
      "Report for test data: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      7446\n",
      "           1       0.44      0.97      0.60       352\n",
      "\n",
      "    accuracy                           0.94      7798\n",
      "   macro avg       0.72      0.96      0.79      7798\n",
      "weighted avg       0.97      0.94      0.95      7798\n",
      "\n",
      "Report for train data: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     17306\n",
      "           1       0.46      0.98      0.62       887\n",
      "\n",
      "    accuracy                           0.94     18193\n",
      "   macro avg       0.73      0.96      0.80     18193\n",
      "weighted avg       0.97      0.94      0.95     18193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score on test data: {}'.format(metrics.accuracy_score(y_test,y_lgs_test)))\n",
    "print('Accuracy score on train data: {}'.format(metrics.accuracy_score(y_train,y_lgs_train)))\n",
    "print('Confusion matrix for test data: \\n', metrics.confusion_matrix(y_test,y_lgs_test))\n",
    "print('Confusion matrix for train data: \\n', metrics.confusion_matrix(y_train,y_lgs_train))\n",
    "print('Report for test data: \\n', metrics.classification_report(y_test,y_lgs_test))\n",
    "print('Report for train data: \\n', metrics.classification_report(y_train,y_lgs_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Logistic_smote', 'score':metrics.accuracy_score(y_test, y_lgs_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_lgs_test), 'precision': metrics.precision_score(y_test, y_lgs_test),\n",
    "    'recall': metrics.recall_score(y_test, y_lgs_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.688576</td>\n",
       "      <td>0.766551</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.974481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic_under</td>\n",
       "      <td>0.515129</td>\n",
       "      <td>0.347956</td>\n",
       "      <td>0.991477</td>\n",
       "      <td>0.915748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic_over</td>\n",
       "      <td>0.578595</td>\n",
       "      <td>0.409953</td>\n",
       "      <td>0.982955</td>\n",
       "      <td>0.935368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic_smote</td>\n",
       "      <td>0.604938</td>\n",
       "      <td>0.438619</td>\n",
       "      <td>0.974432</td>\n",
       "      <td>0.942549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  f1_score  precision    recall     score\n",
       "0        Logistic  0.688576   0.766551  0.625000  0.974481\n",
       "0  Logistic_under  0.515129   0.347956  0.991477  0.915748\n",
       "0   Logistic_over  0.578595   0.409953  0.982955  0.935368\n",
       "0  Logistic_smote  0.604938   0.438619  0.974432  0.942549"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like SMOTE tackles similar problem as other balancing techniques. It improves recall score (tries to identify as many samples from minority class as possible). It might be beneficial in certain tasks (like fraud activity detection or desease identification). However, in the problem of identifying good deal listings it is not only important to correctly label all good deal ones, but also not to mistakenly point at the listings that do not represent a deal a customer might be after. Therefore it is important to find the balance between precision and recall to get better results.\n",
    "\n",
    "In attempt to do so I will try few more resampling techniques:\n",
    "\n",
    "- SMOTENC  - same as SMOTE but it separates categorical variables to treat them differently than numeric ones\n",
    "- ADASYN - oversampling technique - also uses interpolation to generate new samples, but it focuses on generating samples next to the original samples which are wrongly classified using a k-Nearest Neighbors classifier\n",
    "- NearMiss - under-sampling techniques that uses k-nearest neighbor algorithm to select samples from overrepresented class.\n",
    "- EditedNearestNeighbours - under-sampling technique that also applies a nearest-neighbors algorithm.\n",
    "- SMOTEENN - combination of over-sampling and under-sampling techniques.\n",
    "\n",
    "## SMOTENC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# balance data with SMOTENC\n",
    "smote_nc = over_sampling.SMOTENC(random_state=42, categorical_features=[12,13,14,15,16,17,18,19])\n",
    "X_train_smotenc, y_train_smotenc = smote_nc.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr4 = LogisticRegression(solver='lbfgs')\n",
    "lgr4.fit(X_train_smotenc, y_train_smotenc)\n",
    "y_lgsn_test = lgr4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Logistic_smotenc', 'score':metrics.accuracy_score(y_test, y_lgsn_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_lgsn_test), 'precision': metrics.precision_score(y_test, y_lgsn_test),\n",
    "    'recall': metrics.recall_score(y_test, y_lgsn_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADASYN\n",
    "\n",
    "It is another over-sampling technique that also uses interpolation to generate new samples, but it focuses on generating samples next to the original samples which are wrongly classified using a k-Nearest Neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ada = over_sampling.ADASYN(random_state=42)\n",
    "X_train_ada, y_train_ada = ada.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr5 = LogisticRegression(solver='lbfgs')\n",
    "lgr5.fit(X_train_ada, y_train_ada)\n",
    "y_lga_test = lgr5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Logistic_adasyn', 'score':metrics.accuracy_score(y_test, y_lga_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_lga_test), 'precision': metrics.precision_score(y_test, y_lga_test),\n",
    "    'recall': metrics.recall_score(y_test, y_lga_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NearMiss\n",
    "\n",
    "There are three versions of this under-sampling technique in imblearn. I will be using version #3 as it provided the best out of these three versions results. It is a 2-steps algorithm. First, for each negative (in our case 'good deal' sample) sample, their M nearest-neighbors will be kept. Then, the positive samples (non-good deal samples) selected are the one for which the average distance to the N nearest-neighbors is the largest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# resample imbalanced data\n",
    "from imblearn import under_sampling\n",
    "near_miss = under_sampling.NearMiss(random_state=42, version=3)\n",
    "X_train_nm, y_train_nm = near_miss.fit_sample(X_train, y_train)\n",
    "\n",
    "# train classifier\n",
    "lgr6 = LogisticRegression(solver='lbfgs')\n",
    "lgr6.fit(X_train_nm, y_train_nm)\n",
    "y_nm_test = lgr6.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Logistic_nearmiss', 'score':metrics.accuracy_score(y_test, y_nm_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_nm_test), 'precision': metrics.precision_score(y_test, y_nm_test),\n",
    "    'recall': metrics.recall_score(y_test, y_nm_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edited Nearest Neighbor\n",
    "\n",
    "This under-sampling technique applies a nearest-neighbors algorithm. and “edit” the dataset by removing samples which do not agree “enough” with their neighboorhood. For each sample in the class to be under-sampled, the nearest-neighbours are computed and if the selection criterion is not fulfilled, the sample is removed. Two selection criteria are currently available: (i) the majority (i.e., kind_sel='mode') or (ii) all (i.e., kind_sel='all') the nearest-neighbors have to belong to the same class than the sample inspected to keep it in the dataset. Criterion 'mode' resulted in higher precision score ( more balance between precsion and recall), therefore I am using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# resample imbalanced data\n",
    "enn = under_sampling.EditedNearestNeighbours(random_state=42, kind_sel='mode')\n",
    "X_train_enn, y_train_enn = enn.fit_sample(X_train, y_train)\n",
    "\n",
    "# train classifier\n",
    "lgr7 = LogisticRegression(solver='lbfgs')\n",
    "lgr7.fit(X_train_enn, y_train_enn)\n",
    "y_enn_test = lgr7.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Logistic_enn', 'score':metrics.accuracy_score(y_test, y_enn_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_enn_test), 'precision': metrics.precision_score(y_test, y_enn_test),\n",
    "    'recall': metrics.recall_score(y_test, y_enn_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTEENN\n",
    "\n",
    "This combination technique first performs over-sampling using SMOTE and then cleans the data using edited nearest neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\ksushka\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# resample imbalanced data\n",
    "from imblearn import combine\n",
    "smoteenn = combine.SMOTEENN(random_state=42)\n",
    "X_train_smenn, y_train_smenn = smoteenn.fit_sample(X_train, y_train)\n",
    "\n",
    "# train classifier\n",
    "lgr8 = LogisticRegression(solver='lbfgs')\n",
    "lgr8.fit(X_train_smenn, y_train_smenn)\n",
    "y_smenn_test = lgr8.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Logistic_smoteenn', 'score':metrics.accuracy_score(y_test, y_smenn_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_smenn_test), 'precision': metrics.precision_score(y_test, y_smenn_test),\n",
    "    'recall': metrics.recall_score(y_test, y_smenn_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.688576</td>\n",
       "      <td>0.766551</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.974481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic_under</td>\n",
       "      <td>0.515129</td>\n",
       "      <td>0.347956</td>\n",
       "      <td>0.991477</td>\n",
       "      <td>0.915748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic_over</td>\n",
       "      <td>0.578595</td>\n",
       "      <td>0.409953</td>\n",
       "      <td>0.982955</td>\n",
       "      <td>0.935368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic_smote</td>\n",
       "      <td>0.604938</td>\n",
       "      <td>0.438619</td>\n",
       "      <td>0.974432</td>\n",
       "      <td>0.942549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic_smotenc</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.944601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic_adasyn</td>\n",
       "      <td>0.583193</td>\n",
       "      <td>0.414081</td>\n",
       "      <td>0.985795</td>\n",
       "      <td>0.936394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic_nearmiss</td>\n",
       "      <td>0.633554</td>\n",
       "      <td>0.518051</td>\n",
       "      <td>0.815341</td>\n",
       "      <td>0.957425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic_enn</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.973326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic_smoteenn</td>\n",
       "      <td>0.555823</td>\n",
       "      <td>0.387458</td>\n",
       "      <td>0.982955</td>\n",
       "      <td>0.929084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     classifier_name  f1_score  precision    recall     score\n",
       "0           Logistic  0.688576   0.766551  0.625000  0.974481\n",
       "1     Logistic_under  0.515129   0.347956  0.991477  0.915748\n",
       "2      Logistic_over  0.578595   0.409953  0.982955  0.935368\n",
       "3     Logistic_smote  0.604938   0.438619  0.974432  0.942549\n",
       "4   Logistic_smotenc  0.602941   0.445652  0.931818  0.944601\n",
       "5    Logistic_adasyn  0.583193   0.414081  0.985795  0.936394\n",
       "6  Logistic_nearmiss  0.633554   0.518051  0.815341  0.957425\n",
       "7       Logistic_enn  0.707865   0.700000  0.715909  0.973326\n",
       "8  Logistic_smoteenn  0.555823   0.387458  0.982955  0.929084"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_comparison.reset_index(inplace=True)\n",
    "cls_comparison.drop('index', axis=1, inplace=True)\n",
    "cls_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table one can conclude that most of the resampling techniques did improve recall score (percentage of good deals identified), however, none got precision score improved. The best results were shown by ENN, NearMiss and SMOTENC.\n",
    "\n",
    "For training further models I will use other classification algorithms and use three training data sets for each of them: imbalanced original data, ENN for under-sampling and SMOTENC for oversampling. I will continue adding results into comparison dataframe.\n",
    "\n",
    "\n",
    "## k-nearest Neighbors\n",
    "\n",
    "Knn - is another classification algorithms that defines the class based on the majority class of sample's k (hyperparameter to be tuned) nearest neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier on imbalanced data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train,np.array(y_train).reshape(-1,1).ravel())\n",
    "y_knn_test = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'KNN', 'score':metrics.accuracy_score(y_test, y_knn_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_knn_test), 'precision': metrics.precision_score(y_test, y_knn_test),\n",
    "    'recall': metrics.recall_score(y_test, y_knn_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Edited Nearest Neighbours data for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier with resampled data using ENN\n",
    "knn2 = KNeighborsClassifier()\n",
    "knn2.fit(X_train_enn,np.array(y_train_enn).reshape(-1,1).ravel())\n",
    "y_knnenn_test = knn2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'KNN_ENN', 'score':metrics.accuracy_score(y_test, y_knnenn_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_knnenn_test), 'precision': metrics.precision_score(y_test, y_knnenn_test),\n",
    "    'recall': metrics.recall_score(y_test, y_knnenn_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN using SMOTENC resampling technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier with resampled by SMOTENC data\n",
    "knn3 = KNeighborsClassifier()\n",
    "knn3.fit(X_train_smotenc,np.array(y_train_smotenc).reshape(-1,1).ravel())\n",
    "y_knnsm_test = knn3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'KNN_SMOTENC', 'score':metrics.accuracy_score(y_test, y_knnsm_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_knnsm_test), 'precision': metrics.precision_score(y_test, y_knnsm_test),\n",
    "    'recall': metrics.recall_score(y_test, y_knnsm_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.688576</td>\n",
       "      <td>0.766551</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.974481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic_under</td>\n",
       "      <td>0.515129</td>\n",
       "      <td>0.347956</td>\n",
       "      <td>0.991477</td>\n",
       "      <td>0.915748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic_over</td>\n",
       "      <td>0.578595</td>\n",
       "      <td>0.409953</td>\n",
       "      <td>0.982955</td>\n",
       "      <td>0.935368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic_smote</td>\n",
       "      <td>0.604938</td>\n",
       "      <td>0.438619</td>\n",
       "      <td>0.974432</td>\n",
       "      <td>0.942549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic_smotenc</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.944601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic_adasyn</td>\n",
       "      <td>0.583193</td>\n",
       "      <td>0.414081</td>\n",
       "      <td>0.985795</td>\n",
       "      <td>0.936394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic_nearmiss</td>\n",
       "      <td>0.633554</td>\n",
       "      <td>0.518051</td>\n",
       "      <td>0.815341</td>\n",
       "      <td>0.957425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic_enn</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.973326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic_smoteenn</td>\n",
       "      <td>0.555823</td>\n",
       "      <td>0.387458</td>\n",
       "      <td>0.982955</td>\n",
       "      <td>0.929084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.649701</td>\n",
       "      <td>0.616477</td>\n",
       "      <td>0.967684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNN_ENN</td>\n",
       "      <td>0.628429</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.961785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNN_SMOTENC</td>\n",
       "      <td>0.536398</td>\n",
       "      <td>0.404624</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.937933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      classifier_name  f1_score  precision    recall     score\n",
       "0            Logistic  0.688576   0.766551  0.625000  0.974481\n",
       "1      Logistic_under  0.515129   0.347956  0.991477  0.915748\n",
       "2       Logistic_over  0.578595   0.409953  0.982955  0.935368\n",
       "3      Logistic_smote  0.604938   0.438619  0.974432  0.942549\n",
       "4    Logistic_smotenc  0.602941   0.445652  0.931818  0.944601\n",
       "5     Logistic_adasyn  0.583193   0.414081  0.985795  0.936394\n",
       "6   Logistic_nearmiss  0.633554   0.518051  0.815341  0.957425\n",
       "7        Logistic_enn  0.707865   0.700000  0.715909  0.973326\n",
       "8   Logistic_smoteenn  0.555823   0.387458  0.982955  0.929084\n",
       "9                 KNN  0.632653   0.649701  0.616477  0.967684\n",
       "10            KNN_ENN  0.628429   0.560000  0.715909  0.961785\n",
       "11        KNN_SMOTENC  0.536398   0.404624  0.795455  0.937933"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_comparison.reset_index(inplace=True)\n",
    "cls_comparison.drop('index', axis=1, inplace=True)\n",
    "cls_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - support vector machines\n",
    "\n",
    "It is a supervised machine learning algorithm that finds the hyper-plane in n-dimensional feature space. This hyperplace separates two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on imbalanced data\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_svm_train = svm.predict(X_train)\n",
    "y_svm_test = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'SVM', 'score':metrics.accuracy_score(y_test, y_svm_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_svm_test), 'precision': metrics.precision_score(y_test, y_svm_test),\n",
    "    'recall': metrics.recall_score(y_test, y_svm_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with resampled by ENN data\n",
    "svm2 = SVC()\n",
    "svm2.fit(X_train_enn, y_train_enn)\n",
    "y_svmenn_test = svm2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'SVM_ENN', 'score':metrics.accuracy_score(y_test, y_svmenn_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_svmenn_test), 'precision': metrics.precision_score(y_test, y_svmenn_test),\n",
    "    'recall': metrics.recall_score(y_test, y_svmenn_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with resampled by SMOTENC data\n",
    "svm3 = SVC()\n",
    "svm3.fit(X_train_smotenc, y_train_smotenc)\n",
    "y_svmsm_test = svm3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'SVM_SMOTENC', 'score':metrics.accuracy_score(y_test, y_svmsm_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_svmsm_test), 'precision': metrics.precision_score(y_test, y_svmsm_test),\n",
    "    'recall': metrics.recall_score(y_test, y_svmsm_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table it can be concluded that KNN algorithm did not provide any improvement. Support Vector Machine one delivered better results as before with the largest precision score for the case when trained over imbalanced data and with the most balanced and both highest scores for precision and recall when trained on ENN balanced data. In this case the F1 score is the largest so far also with 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "It is a supervised learning algorithm that separates the data at each node based on certain criteria it learns from trained data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on imbalanced data\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "y_dt_test = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Decision Tree', 'score':metrics.accuracy_score(y_test, y_dt_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_dt_test), 'precision': metrics.precision_score(y_test, y_dt_test),\n",
    "    'recall': metrics.recall_score(y_test, y_dt_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desicion Tree with ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on ENN balanced data\n",
    "dtc2 = DecisionTreeClassifier()\n",
    "dtc2.fit(X_train_enn, y_train_enn)\n",
    "y_dtenn_test = dtc2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Decision Tree ENN', 'score':metrics.accuracy_score(y_test, y_dtenn_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_dtenn_test), 'precision': metrics.precision_score(y_test, y_dtenn_test),\n",
    "    'recall': metrics.recall_score(y_test, y_dtenn_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree with SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on SMOTENC balanced data\n",
    "dtc3 = DecisionTreeClassifier()\n",
    "dtc3.fit(X_train_smotenc, y_train_smotenc)\n",
    "y_dtsm_test = dtc3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Decision Tree SMOTENC', 'score':metrics.accuracy_score(y_test, y_dtsm_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_dtsm_test), 'precision': metrics.precision_score(y_test, y_dtsm_test),\n",
    "    'recall': metrics.recall_score(y_test, y_dtsm_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "It is an ensemble algorithm that uses multiple decision trees (100 trees in sklearn function) and combines the results from them to make a classification decision.  Each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set. Random forests achieve a reduced variance by combining diverse trees, sometimes at the cost of a slight increase in bias. In practice the variance reduction is often significant hence yielding an overall better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on imbalanced data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "y_rf_test = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Random Forest', 'score':metrics.accuracy_score(y_test, y_rf_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_rf_test), 'precision': metrics.precision_score(y_test, y_rf_test),\n",
    "    'recall': metrics.recall_score(y_test, y_rf_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on enn balanced data\n",
    "rfc2 = RandomForestClassifier()\n",
    "rfc2.fit(X_train_enn, y_train_enn)\n",
    "y_rfenn_test = rfc2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Random Forest ENN', 'score':metrics.accuracy_score(y_test, y_rfenn_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_rfenn_test), 'precision': metrics.precision_score(y_test, y_rfenn_test),\n",
    "    'recall': metrics.recall_score(y_test, y_rfenn_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on SMOTENC balanced data\n",
    "rfc3 = RandomForestClassifier()\n",
    "rfc3.fit(X_train_smotenc, y_train_smotenc)\n",
    "y_rfsm_test = rfc3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Random Forest SMOTENC', 'score':metrics.accuracy_score(y_test, y_rfsm_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_rfsm_test), 'precision': metrics.precision_score(y_test, y_rfsm_test),\n",
    "    'recall': metrics.recall_score(y_test, y_rfsm_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "\n",
    "It is also an ensemble method that fits a sequence of weak learners (i.e., models that are only slightly better than random guessing, such as small decision trees) on repeatedly modified versions of the data. The predictions from all of them are then combined through a weighted majority vote (or sum) to produce the final prediction. \n",
    "\n",
    "The data modifications at each so-called boosting iteration consist of applying weights to each of the training samples. Initially, those weights are all set to 1/N, so that the first step simply trains a weak learner on the original data. For each successive iteration, the sample weights are individually modified and the learning algorithm is reapplied to the reweighted data. At a given step, those training examples that were incorrectly predicted by the boosted model induced at the previous step have their weights increased, whereas the weights are decreased for those that were predicted correctly. As iterations proceed, examples that are difficult to predict receive ever-increasing influence. Each subsequent weak learner is thereby forced to concentrate on the examples that are missed by the previous ones in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on imbalanced data\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train,y_train)\n",
    "y_ada_test = ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'AdaBoost', 'score':metrics.accuracy_score(y_test, y_ada_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_ada_test), 'precision': metrics.precision_score(y_test, y_ada_test),\n",
    "    'recall': metrics.recall_score(y_test, y_ada_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost with ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on ENN balanced data\n",
    "ada2 = AdaBoostClassifier()\n",
    "ada2.fit(X_train_enn, y_train_enn)\n",
    "y_adaenn_test = ada2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'AdaBoost ENN', 'score':metrics.accuracy_score(y_test, y_adaenn_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_adaenn_test), 'precision': metrics.precision_score(y_test, y_adaenn_test),\n",
    "    'recall': metrics.recall_score(y_test, y_adaenn_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost with SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with smotenc\n",
    "ada3 = AdaBoostClassifier()\n",
    "ada3.fit(X_train_smotenc, y_train_smotenc)\n",
    "y_adasm_test = ada3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'AdaBoost SMOTENC', 'score':metrics.accuracy_score(y_test, y_adasm_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_adasm_test), 'precision': metrics.precision_score(y_test, y_adasm_test),\n",
    "    'recall': metrics.recall_score(y_test, y_adasm_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "It is another ensemble model that uses weak prediction models, typically decision trees. It builds the model in a stage-wise fashion like other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on imbalanced data\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc= GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "y_gb_test = gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Gradient Boosting', 'score':metrics.accuracy_score(y_test, y_gb_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_gb_test), 'precision': metrics.precision_score(y_test, y_gb_test),\n",
    "    'recall': metrics.recall_score(y_test, y_gb_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting with ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on ENN balanced data\n",
    "gbc2 = GradientBoostingClassifier()\n",
    "gbc2.fit(X_train_enn, y_train_enn)\n",
    "y_gbenn_test = gbc2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Gradient Boosting ENN', 'score':metrics.accuracy_score(y_test, y_gbenn_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_gbenn_test), 'precision': metrics.precision_score(y_test, y_gbenn_test),\n",
    "    'recall': metrics.recall_score(y_test, y_gbenn_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting with SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc3 = GradientBoostingClassifier()\n",
    "gbc3.fit(X_train_smotenc, y_train_smotenc)\n",
    "y_gbsm_test = gbc3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scores to comparison dataframe\n",
    "a = {'classifier_name':'Gradient Boosting SMOTENC', 'score':metrics.accuracy_score(y_test, y_gbsm_test), \n",
    "     'f1_score': metrics.f1_score(y_test, y_gbsm_test), 'precision': metrics.precision_score(y_test, y_gbsm_test),\n",
    "    'recall': metrics.recall_score(y_test, y_gbsm_test)}\n",
    "cls_comparison = pd.concat([cls_comparison, pd.DataFrame([a])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.834286</td>\n",
       "      <td>0.839080</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.985124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.866120</td>\n",
       "      <td>0.834211</td>\n",
       "      <td>0.900568</td>\n",
       "      <td>0.987433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.834512</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.838068</td>\n",
       "      <td>0.984996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.716561</td>\n",
       "      <td>0.815217</td>\n",
       "      <td>0.639205</td>\n",
       "      <td>0.977174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Random Forest ENN</td>\n",
       "      <td>0.847185</td>\n",
       "      <td>0.802030</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.985381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.981021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Decision Tree SMOTENC</td>\n",
       "      <td>0.815321</td>\n",
       "      <td>0.786280</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.982688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AdaBoost ENN</td>\n",
       "      <td>0.848958</td>\n",
       "      <td>0.783654</td>\n",
       "      <td>0.926136</td>\n",
       "      <td>0.985124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Decision Tree ENN</td>\n",
       "      <td>0.826203</td>\n",
       "      <td>0.780303</td>\n",
       "      <td>0.877841</td>\n",
       "      <td>0.983329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gradient Boosting ENN</td>\n",
       "      <td>0.840467</td>\n",
       "      <td>0.773270</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.984227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.688576</td>\n",
       "      <td>0.766551</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.974481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Random Forest SMOTENC</td>\n",
       "      <td>0.839599</td>\n",
       "      <td>0.751121</td>\n",
       "      <td>0.951705</td>\n",
       "      <td>0.983586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVM_ENN</td>\n",
       "      <td>0.751055</td>\n",
       "      <td>0.743733</td>\n",
       "      <td>0.758523</td>\n",
       "      <td>0.977302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AdaBoost SMOTENC</td>\n",
       "      <td>0.824499</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.994318</td>\n",
       "      <td>0.980893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic_enn</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.973326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Gradient Boosting SMOTENC</td>\n",
       "      <td>0.812207</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.982955</td>\n",
       "      <td>0.979482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.649701</td>\n",
       "      <td>0.616477</td>\n",
       "      <td>0.967684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNN_ENN</td>\n",
       "      <td>0.628429</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.961785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic_nearmiss</td>\n",
       "      <td>0.633554</td>\n",
       "      <td>0.518051</td>\n",
       "      <td>0.815341</td>\n",
       "      <td>0.957425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVM_SMOTENC</td>\n",
       "      <td>0.658754</td>\n",
       "      <td>0.505311</td>\n",
       "      <td>0.946023</td>\n",
       "      <td>0.955758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic_smotenc</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.944601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic_smote</td>\n",
       "      <td>0.604938</td>\n",
       "      <td>0.438619</td>\n",
       "      <td>0.974432</td>\n",
       "      <td>0.942549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic_adasyn</td>\n",
       "      <td>0.583193</td>\n",
       "      <td>0.414081</td>\n",
       "      <td>0.985795</td>\n",
       "      <td>0.936394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic_over</td>\n",
       "      <td>0.578595</td>\n",
       "      <td>0.409953</td>\n",
       "      <td>0.982955</td>\n",
       "      <td>0.935368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNN_SMOTENC</td>\n",
       "      <td>0.536398</td>\n",
       "      <td>0.404624</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.937933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic_smoteenn</td>\n",
       "      <td>0.555823</td>\n",
       "      <td>0.387458</td>\n",
       "      <td>0.982955</td>\n",
       "      <td>0.929084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic_under</td>\n",
       "      <td>0.515129</td>\n",
       "      <td>0.347956</td>\n",
       "      <td>0.991477</td>\n",
       "      <td>0.915748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              classifier_name  f1_score  precision    recall     score\n",
       "18              Random Forest  0.834286   0.839080  0.829545  0.985124\n",
       "21                   AdaBoost  0.866120   0.834211  0.900568  0.987433\n",
       "24          Gradient Boosting  0.834512   0.830986  0.838068  0.984996\n",
       "12                        SVM  0.716561   0.815217  0.639205  0.977174\n",
       "19          Random Forest ENN  0.847185   0.802030  0.897727  0.985381\n",
       "15              Decision Tree  0.789773   0.789773  0.789773  0.981021\n",
       "17      Decision Tree SMOTENC  0.815321   0.786280  0.846591  0.982688\n",
       "22               AdaBoost ENN  0.848958   0.783654  0.926136  0.985124\n",
       "16          Decision Tree ENN  0.826203   0.780303  0.877841  0.983329\n",
       "25      Gradient Boosting ENN  0.840467   0.773270  0.920455  0.984227\n",
       "0                    Logistic  0.688576   0.766551  0.625000  0.974481\n",
       "20      Random Forest SMOTENC  0.839599   0.751121  0.951705  0.983586\n",
       "13                    SVM_ENN  0.751055   0.743733  0.758523  0.977302\n",
       "23           AdaBoost SMOTENC  0.824499   0.704225  0.994318  0.980893\n",
       "7                Logistic_enn  0.707865   0.700000  0.715909  0.973326\n",
       "26  Gradient Boosting SMOTENC  0.812207   0.692000  0.982955  0.979482\n",
       "9                         KNN  0.632653   0.649701  0.616477  0.967684\n",
       "10                    KNN_ENN  0.628429   0.560000  0.715909  0.961785\n",
       "6           Logistic_nearmiss  0.633554   0.518051  0.815341  0.957425\n",
       "14                SVM_SMOTENC  0.658754   0.505311  0.946023  0.955758\n",
       "4            Logistic_smotenc  0.602941   0.445652  0.931818  0.944601\n",
       "3              Logistic_smote  0.604938   0.438619  0.974432  0.942549\n",
       "5             Logistic_adasyn  0.583193   0.414081  0.985795  0.936394\n",
       "2               Logistic_over  0.578595   0.409953  0.982955  0.935368\n",
       "11                KNN_SMOTENC  0.536398   0.404624  0.795455  0.937933\n",
       "8           Logistic_smoteenn  0.555823   0.387458  0.982955  0.929084\n",
       "1              Logistic_under  0.515129   0.347956  0.991477  0.915748"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_comparison.reset_index(inplace=True)\n",
    "cls_comparison.drop('index', axis=1, inplace=True)\n",
    "cls_comparison.sort_values(['precision', 'f1_score','recall'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am sorting the scores in the following order: precision, f1 and recall. As I have discussed earlier, the biggest interest here not only to correctly identify good deal listings but also not to mistakenly label regular listing as a 'good deal' ones. Therefore I am trying to get the highest precision score. The best results so far were achieved by the ensemble algorithms trained on imbalanced data. They can be rated in the following order:\n",
    "\n",
    "- Random Forest with almost 0.85 precision score\n",
    "- AdaBoosting with over 0.83 precision score\n",
    "- Gradient Boosting with about 0.83 precision scores\n",
    "\n",
    "Same algorithms trained on Edited Nearest Neighbours balanced data showed slightly lower precision scores but higher recall scores (identified correctly larger number of actual 'good deal' listings than the ones trained on imbalanced data.\n",
    "\n",
    "All of the 'winning' algorithms represent ensemble methods where training data is resampled within algorithm to train separate models. It might explain why these algorithms perform better when working with original imbalanced data.\n",
    "\n",
    "Further, I will try to combine these top three algorithms in voting classifier (with hard voting = majority vote rule) to see if there can be any improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = RandomForestClassifier()\n",
    "clf2 = AdaBoostClassifier()\n",
    "clf3 = GradientBoostingClassifier()\n",
    "eclf = VotingClassifier(estimators=[('rf', clf1), ('D', clf2), ('gb', clf3)], voting='hard')\n",
    "eclf.fit(X_train, y_train)\n",
    "y_v_test = eclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7391   55]\n",
      " [  48  304]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      7446\n",
      "           1       0.85      0.86      0.86       352\n",
      "\n",
      "    accuracy                           0.99      7798\n",
      "   macro avg       0.92      0.93      0.92      7798\n",
      "weighted avg       0.99      0.99      0.99      7798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_v_test))\n",
    "print(metrics.classification_report(y_test,y_v_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It yield about the same result for precision score, but improved recall and hence f1 score slightly.\n",
    "\n",
    "For further improvement it might be worth to play around with features (maybe taking less of them into account or creating interdependencies between them as separate variables) and/or adjust model parameters.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
